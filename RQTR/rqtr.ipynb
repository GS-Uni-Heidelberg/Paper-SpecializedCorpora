{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQTR (for Lemmatized Corpora)\n",
    "\n",
    "With this notebook you can calculate the RQTR(n) values for a lemmatized corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "from src.corpus import Corpus\n",
    "from src.metrics import rqtr_lemma\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import json\n",
    "from src.load_data import load_files\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data...\n",
    "\n",
    "Put the path to your corpus in the variable `CORPUSDIR`.\n",
    "\n",
    "I assume that the data is a set of json files, each containing a list of lemmata under the key 'lemmas'.\n",
    "If you have a different format, you need to adjust the code accordingly. The result should be a list of lists of lemmata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the path to the directory containing the corpus files here\n",
    "CORPUSDIR = '/home/brunobrocai/Data/MoWiKo/Paper-themKorp/full'\n",
    "\n",
    "docs, metadata = load_files(CORPUSDIR)\n",
    "corpus = Corpus(docs, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking the ANY NUMBER OF (!) base terms for RQTR calculation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking base terms\n",
    "base_terms = (('kÃ¼nstlich', 'Intelligenz'), 'KI', 'AI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it comes!\n",
    "\n",
    "Let's calculcate baseline QTR values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, core_term =rqtr_lemma.qtr_baseline(\n",
    "    base_terms, corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate RQTR values for all terms in the corpus -- at least those that cooccur with the base terms at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurence_values = rqtr_lemma.count_cooccurence(\n",
    "    base_terms,\n",
    "    corpus,\n",
    "    max_ngram_len=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we just used returns a dictionary with the RQTR values for all terms in the corpus. We can now perform some Pandas DataFrame magic to get a nice overview of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rqtrn_table = rqtr_lemma.cooccurence_to_metric(\n",
    "    cooccurence_values,\n",
    "    b,\n",
    "    metric='rqtrn'\n",
    ")\n",
    "rqtrn_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values with RQTRN > 40\n",
    "filtered_df = rqtrn_table[(rqtrn_table['rqtrn'] > 40)]\n",
    "# Get the values with count > 3\n",
    "filtered_df = filtered_df[filtered_df['count'] > 2]\n",
    "\n",
    "filtered_df['weight'] = filtered_df['rqtrn'] / 100\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Corpus Creation\n",
    "Now we can retrieve documents based on the wordlist we created with the RQTR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.corpus_creation import document_retriever as dr\n",
    "\n",
    "\n",
    "wordlist = filtered_df['value'].tolist()\n",
    "wordlist.extend(base_terms)\n",
    "found_docs = dr.match_wordlist(corpus, wordlist, min=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in found_docs:\n",
    "    print(doc[1]['h1'])\n",
    "    print(doc[1]['url'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_wordlist = dict(filtered_df[['value', 'weight']].values.tolist())\n",
    "found_docs = dr.match_weighted_wordlist(corpus, weighted_wordlist, min=2)\n",
    "\n",
    "for doc in found_docs:\n",
    "    print(doc[1]['h1'])\n",
    "    print(doc[1]['url'])\n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
