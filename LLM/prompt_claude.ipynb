{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY_CLAUDE\")\n",
    "client = anthropic.Anthropic(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = yaml.safe_load(\n",
    "    open('setup/prompts.yaml')\n",
    ")['regex_query_gen']['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42295dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "    max_tokens=16000,\n",
    "    thinking={\n",
    "        \"type\": \"enabled\",\n",
    "        \"budget_tokens\": 10000\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af3b2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llm-generated-prompt.txt', 'w') as f:\n",
    "    f.write(str(completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "241a0bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Regulärer Ausdruck für ein KI-Korpus\n",
      "\n",
      "Hier ist ein umfassender regulärer Ausdruck für dein KI-Korpus, der auf hohe Precision und Recall ausgelegt ist:\n",
      "\n",
      "```python\n",
      "r\"\"\"(?xi)\n",
      "# Grundbegriffe und Abkürzungen\n",
      "\\b(KI\\b|k[üu]nstlich[a-zäöü]* intelligenz|artificial intelligence|AI\\b)\n",
      "\n",
      "# Lernverfahren\n",
      "|(machine learning|maschinell[a-zäöü]* lern[a-zäöü]*|deep learning|tief[a-zäöü]* lern[a-zäöü]*)\n",
      "|(supervised learning|[üu]berwacht[a-zäöü]* lern[a-zäöü]*|unsupervised learning|un[üu]berwacht[a-zäöü]* lern[a-zäöü]*)\n",
      "|(reinforcement learning|best[äa]rk[a-zäöü]* lern[a-zäöü]*|selbst[üu]berwacht[a-zäöü]* lern[a-zäöü]*|self-supervised learning)\n",
      "|(transfer learning|few-shot learning|zero-shot learning|one-shot learning|multimodal[a-zäöü]* lern[a-zäöü]*)\n",
      "|(federated learning|f[öo]deriert[a-zäöü]* lern[a-zäöü]*)\n",
      "\n",
      "# Modelltypen und Architektur\n",
      "|(neural[a-zäöü]* net[a-zäöü]*|neuronale[a-zäöü]* net[a-zäöü]*|neuronale[a-zäöü]* netzwerk[a-zäöü]*)\n",
      "|(transformer[a-zäöü]*|attention mechanism|attention-mechanismus|autoencoder)\n",
      "|(generative adversarial network[a-zäöü]*|generativ[a-zäöü]* gegnerisch[a-zäöü]* net[a-zäöü]*)\n",
      "|(convolutional neural network[a-zäöü]*|faltungsnet[a-zäöü]*)\n",
      "|(recurrent neural network[a-zäöü]*|rekurrent[a-zäöü]* neural[a-zäöü]* net[a-zäöü]*)\n",
      "|(large language model[a-zäöü]*|gro(?:ß|ss)[a-zäöü]* sprachmodell[a-zäöü]*)\n",
      "|(foundation model[a-zäöü]*|fundament-modell[a-zäöü]*|grundlagenmodell[a-zäöü]*)\n",
      "|(multimodal[a-zäöü]* modell[a-zäöü]*|multimodal[a-zäöü]* AI|multimodal[a-zäöü]* KI)\n",
      "|(generativ[a-zäöü]* KI|generativ[a-zäöü]* AI|generative AI)\n",
      "\n",
      "# KI-Spezifische Abkürzungen (mit Kontext)\n",
      "|((?<!C)NN\\b|CNN(?! news)|RNN\\b|LSTM\\b|GRU\\b|GAN(?! member| clan))\n",
      "|(NLP(?! therapie| therapy)|NLU\\b|NLG\\b)\n",
      "|(LLM[s]?\\b|RLHF\\b|XAI\\b)\n",
      "\n",
      "# Sprachverarbeitung\n",
      "|(natural language processing|sprachverarbeitung|computerlinguistik)\n",
      "|(prompt[a-zäöü]* engineering|prompt[a-zäöü]* design|prompting)\n",
      "|(embedding[a-zäöü]*|token[a-zäöü]*|tokenisierung|tokenization)\n",
      "|(fine(?:-|\\s)tuning|feinabstimmung|parameter[a-zäöü]* lern[a-zäöü]*)\n",
      "|(sprachverst[äa]ndnis|language understanding|sprachmodellierung)\n",
      "|(semantisch[a-zäöü]* such[a-zäöü]*|semantic search|vektorsuche|vector search)\n",
      "\n",
      "# KI-Anwendungen\n",
      "|(chatbot[a-zäöü]*|conversational AI|konversationell[a-zäöü]* KI)\n",
      "|(sprachassistent[a-zäöü]*|virtuell[a-zäöü]* assistent[a-zäöü]*)\n",
      "|(bilderkennung|bildklassifizierung|objekterkennung|object detection)\n",
      "|(spracherkennung|textgenerierung|bildgenerierung|content generation)\n",
      "|([üu]bersetzungssystem[a-zäöü]*|maschinell[a-zäöü]* [üu]bersetzung)\n",
      "|(empfehlungssystem[a-zäöü]*|recommendation engine|recommendation system)\n",
      "|(gesichtserkennung|face recognition|sentimentanalyse)\n",
      "|(text-to-speech|sprachsynthese|speech-to-text|text-to-image|text-zu-bild)\n",
      "|(pr[äa]diktiv[a-zäöü]* analytik|predictive analytics)\n",
      "|(autonom[a-zäöü]* fahr[a-zäöü]*|autonomous driving|selbstfahrend[a-zäöü]*)\n",
      "\n",
      "# Prominente KI-Modelle\n",
      "|(GPT-[0-9]+(?:-turbo)?|GPT4?|GPT-4|ChatGPT|InstructGPT)\n",
      "|(BERT\\b|LLaMA|Claude\\b|Gemini(?:\\s(?:Pro|Ultra))?|PaLM\\b)\n",
      "|(DALL[-\\s]?E|Midjourney|Stable Diffusion|Imagen)\n",
      "|(Copilot|Bing Chat|Bard\\b|Anthropic Claude|Google Gemini)\n",
      "|(Falcon(?:\\s?LLM)?|Mistral(?:\\s?AI)?|Phi-[0-9]|Pythia)\n",
      "\n",
      "# Frameworks und Tools\n",
      "|(TensorFlow|PyTorch|Keras|JAX|Hugging Face|Transformers)\n",
      "|(LangChain|llamaindex|embedchain|chromadb|milvus|pinecone)\n",
      "|(OpenVINO|ONNX|MLflow|Ray\\b|Kubernetes for AI|Kubeflow)\n",
      "\n",
      "# Unternehmen und Organisationen\n",
      "|(OpenAI|DeepMind|Anthropic|Cohere|Hugging Face)\n",
      "|(Microsoft(?:\\sAI)?|Google(?:\\sAI)?|Meta(?:\\sAI)?|NVIDIA(?:\\sAI)?)\n",
      "|(IBM(?:\\sWatson)?|Stability AI|Inflection AI|Aleph Alpha)\n",
      "\n",
      "# KI-Ethik und -Regulierung\n",
      "|(KI-Ethik|AI ethics|verantwortungsvolle[a-zäöü]* KI|responsible AI)\n",
      "|(erkl[äa]rbar[a-zäöü]* KI|explainable AI|KI-Regulierung|AI regulation)\n",
      "|(KI-Sicherheit|AI safety|KI-Risik[a-zäöü]*|AI risk[a-zäöü]*)\n",
      "|(KI-Verzerrung|AI bias|algorithmic bias|algorithmisch[a-zäöü]* verzerrung)\n",
      "|(KI-Governance|AI governance|KI-Transparenz|AI transparency)\n",
      "|(menschenzentriert[a-zäöü]* KI|human-centered AI|vertrauensw[üu]rdig[a-zäöü]* KI)\n",
      "\n",
      "# KI-Forscher und Persönlichkeiten\n",
      "|(Geoffrey Hinton|Yoshua Bengio|Yann LeCun|Andrew Ng|Demis Hassabis)\n",
      "|(Sam Altman|Dario Amodei|Fei-Fei Li|Ian Goodfellow|Andrej Karpathy)\n",
      "|(Ilya Sutskever|Oriol Vinyals|Jeff Dean|Turing-Test|Alan Turing)\n",
      "\n",
      "# KI-Konzepte\n",
      "|(Singularit[äa]t|technological singularity|superintelligenz|AGI\\b)\n",
      "|(allgemeine KI|general intelligence|artificial general intelligence)\n",
      "|(halluzination[a-zäöü]*|KI-halluzination[a-zäöü]*|AI hallucination[a-zäöü]*)\n",
      "|(prompt injection|jailbreak[a-zäöü]*|red teaming|adversarial example[a-zäöü]*)\n",
      "\n",
      "# KI-Zusammensetzungen\n",
      "|(KI-[a-zäöü]+|AI-[a-zA-Z]+)\n",
      "|(KI\\s(?:system|tool|modell|anwendung|lösung|algorithmus|assistent|technologie))\n",
      "|(AI\\s(?:system|tool|model|application|solution|algorithm|assistant|technology))\n",
      "\\b\"\"\"\n",
      "```\n",
      "\n",
      "## Erläuterung\n",
      "\n",
      "Dieser reguläre Ausdruck:\n",
      "\n",
      "1. **Nutzt die `(?xi)`-Flag** für erhöhte Lesbarkeit und Ignorieren von Groß-/Kleinschreibung\n",
      "2. **Ist thematisch gruppiert** für leichtere Wartung\n",
      "3. **Vermeidet mehrdeutige Begriffe** wie \"Daten\" oder andere allgemeine Tech-Begriffe\n",
      "4. **Enthält Kontext-Qualifizierer** für potenziell mehrdeutige Abkürzungen (z.B. CNN mit Negativ-Lookahead für \"CNN news\")\n",
      "5. **Berücksichtigt verschiedene Flexionen** durch Wildcards für Endungen\n",
      "6. **Deckt umfassend ab**:\n",
      "   - Grundlegende KI-Terminologie\n",
      "   - Lernverfahren und Modellarchitekturen\n",
      "   - Spezifische KI-Modelle und Produkte\n",
      "   - Unternehmen und Persönlichkeiten\n",
      "   - Ethische und gesellschaftliche Aspekte\n",
      "   - Anwendungsbereiche\n",
      "\n",
      "Durch diese Struktur solltest du eine gute Balance zwischen Precision und Recall erzielen. Der Ausdruck ist so konzipiert, dass er spezifisch genug ist, um Texte über andere Themen auszuschließen, aber umfassend genug, um den Großteil des KI-Diskurses abzudecken.\n"
     ]
    }
   ],
   "source": [
    "text_blocks = [block for block in completion.content if hasattr(block, 'text')]\n",
    "if text_blocks:\n",
    "    response_text = text_blocks[0].text\n",
    "    print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
