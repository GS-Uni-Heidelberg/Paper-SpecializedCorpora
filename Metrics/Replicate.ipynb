{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicate\n",
    "\n",
    "With this notebook, you can replicate the numbers and figures from our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.corpus import Corpus\n",
    "from src.metrics import keyness\n",
    "from src.corpus_creation import document_retriever as dr\n",
    "from src.corpus_creation import handle_wordlists as hw\n",
    "from src.load_data import load_files\n",
    "from src.metrics import rqtr_lemma\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data...\n",
    "\n",
    "Put the path to your corpus in the variable `CORPUSDIR`.\n",
    "\n",
    "I assume that the data is a set of json files, each containing a list of lemmata under the key 'lemmas'.\n",
    "If you have a different format, you need to adjust the code accordingly. The result should be a list of lists of lemmata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the path to the directory containing the corpus files here\n",
    "CORPUSDIR = '/home/brunobrocai/Data/MoWiKo/replicate/final_corpus'\n",
    "\n",
    "docs, metadata = load_files(CORPUSDIR)\n",
    "corpus = Corpus(docs, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two sets of core terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_terms = [\n",
    "    [('künstlich', 'Intelligenz'), ('KI',)],\n",
    "    [('künstlich', 'Intelligenz'), ('Roboter',), ('Chatbot',)],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the two core term sets, we create two study/reference corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_ref_corpora = {}\n",
    "for i, core_term in enumerate(core_terms):\n",
    "    hits = dr.match_wordlist(\n",
    "        corpus, core_term, min=1\n",
    "    )\n",
    "\n",
    "    study_corpus = dr.corpus_from_found(\n",
    "        hits, source_corpus=corpus,\n",
    "        goal_corpus='FrequencyCorpus'\n",
    "    )\n",
    "    reference_corpus = dr.corpus_from_notfound(\n",
    "        hits, source_corpus=corpus,\n",
    "        goal_corpus='FrequencyCorpus'\n",
    "    )\n",
    "    study_ref_corpora[i] = (study_corpus, reference_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define some (admitedly, long and inelegant) functions to calculate the keyness metrics and execute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlists = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyness_query(study_corpus, reference_corpus, method, core_terms):\n",
    "    keynesses = keyness.keyword_list(\n",
    "        study_corpus, reference_corpus,\n",
    "        metric=method,\n",
    "        min_docs=5,\n",
    "        smoothing=0.0001,\n",
    "        max_ngram_len=2,\n",
    "        filter_stopwords=True,\n",
    "    )\n",
    "    if method == 'odds_ratio':\n",
    "        filtered_df = keynesses[(keynesses['Keyness'] > 1.0)]\n",
    "    elif method == 'log_likelihood_rayson':\n",
    "        filtered_df = keynesses[(keynesses['Keyness'] > 15.13)]\n",
    "\n",
    "    filtered_df = hw.top_x_with_core(50, 'Keyness', filtered_df, core_terms)\n",
    "\n",
    "    wordlist = filtered_df['Term'].tolist()\n",
    "    return wordlist\n",
    "\n",
    "def rqtr(\n",
    "    full_corpus,\n",
    "    study_corpus, reference_corpus,\n",
    "    core_terms,\n",
    "):\n",
    "    b, core_term =rqtr_lemma.qtr_baseline(\n",
    "        core_terms, full_corpus\n",
    "    )\n",
    "    cooccurence_values = rqtr_lemma.count_cooccurence(\n",
    "        core_terms,\n",
    "        full_corpus,\n",
    "        max_ngram_len=2,\n",
    "    )\n",
    "    rqtrn_table = rqtr_lemma.cooccurence_to_metric(\n",
    "        cooccurence_values,\n",
    "        b,\n",
    "        metric='rqtrn',\n",
    "        min_docs=5,\n",
    "    )\n",
    "    keynesses = keyness.keyword_list(\n",
    "        study_corpus, reference_corpus,\n",
    "        metric='log_likelihood_rayson',\n",
    "        min_docs=5,\n",
    "        smoothing=0.0001,\n",
    "        max_ngram_len=2,\n",
    "        filter_stopwords=True,\n",
    "    )\n",
    "    filtered_df = rqtrn_table[(rqtrn_table['RQTRN'] > 0)]\n",
    "\n",
    "    # Add column LL and then filter\n",
    "    filtered_df['LL'] = rqtrn_table['Term'].map(\n",
    "        keynesses.set_index('Term')['Keyness']\n",
    "    )\n",
    "    filtered_df = filtered_df[filtered_df['LL'] > 15.13]\n",
    "\n",
    "    filtered_df = hw.top_x_with_core(50, 'RQTRN', filtered_df, core_terms)\n",
    "\n",
    "    wordlist = filtered_df['Term'].tolist()\n",
    "\n",
    "    return wordlist\n",
    "\n",
    "wordlists['rqtr'] = rqtr(\n",
    "    corpus,\n",
    "    study_ref_corpora[0][0], study_ref_corpora[0][1],\n",
    "    core_terms[0],\n",
    ")\n",
    "wordlists['rqtr_BT2'] = rqtr(\n",
    "    corpus,\n",
    "    study_ref_corpora[1][0], study_ref_corpora[1][1],\n",
    "    core_terms[1],\n",
    ")\n",
    "for method in ['odds_ratio', 'log_likelihood_rayson']:\n",
    "    wordlists[method] = keyness_query(\n",
    "        study_ref_corpora[0][0], study_ref_corpora[0][1],\n",
    "        method,\n",
    "        core_terms[0]\n",
    "    )\n",
    "    wordlists[method + '_BT2'] = keyness_query(\n",
    "        study_ref_corpora[1][0], study_ref_corpora[1][1],\n",
    "        method,\n",
    "        core_terms[1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-defined queries we can just load from `custom_queries.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.misc import custom_queries\n",
    "\n",
    "wordlists['Baseline'] = custom_queries.BASELINE\n",
    "wordlists['Subjective (1)'] = custom_queries.SUBJECTIVE_1\n",
    "wordlists['Subjective (2)'] = custom_queries.SUBJECTIVE_2\n",
    "wordlists['LLM-Regex'] = custom_queries.KI_REGEX_LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collocations are also best loaded from a file because they take long to compute. If you want to replicate this part, head over to the `collocations.ipynb` notebook and run the code there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the cooccurences takes a longer time, so we load precomputed values\n",
    "\n",
    "def load_collocs_csv(\n",
    "    filename,\n",
    "    base_terms=[('künstlich', 'Intelligenz'), 'KI']\n",
    "):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df[df['Doc_Freq'] > 4]\n",
    "    filtered_df = hw.top_x_with_core(50, 'Stat', df, core_terms[0])\n",
    "    wordlist = filtered_df['Term'].tolist()\n",
    "    return wordlist\n",
    "\n",
    "\n",
    "wordlists['coll-Absatz-logdice'] = load_collocs_csv('wordlists/collocations/windowsizeParagraph-logdice.csv')\n",
    "wordlists['coll-Absatz-npmi'] = load_collocs_csv('wordlists/collocations/windowsizeParagraph-npmi.csv')\n",
    "wordlists['coll-5-logdice'] = load_collocs_csv('wordlists/collocations/windowsize5-logdice.csv')\n",
    "wordlists['coll-5-npmi'] = load_collocs_csv('wordlists/collocations/windowsize5-nmpi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the resulting wordlists so that we can inspect them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Save the wordlists to files\n",
    "\n",
    "GOALDIR = 'wordlists/queries/'\n",
    "\n",
    "if not os.path.exists(GOALDIR):\n",
    "    os.makedirs(GOALDIR)\n",
    "\n",
    "for name, wordlist in wordlists.items():\n",
    "    if isinstance(wordlist, str):\n",
    "        wordlist = [wordlist]\n",
    "    filename = GOALDIR + name + '.txt'\n",
    "    if os.path.exists(filename):\n",
    "        print(f'File {filename} already exists. Skipping.')\n",
    "        continue\n",
    "    with open(filename, 'w') as f:\n",
    "        for term in wordlist:\n",
    "            f.write(str(term) + '\\n')\n",
    "    print(f'Wordlist {name} saved to {GOALDIR + name}.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a function that evaluates the queries at different absolute frequency thesholds and run it.\n",
    "\n",
    "Looking at thresholds from 1 to 30 is enough to see all relevant phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def results_for_methods(\n",
    "    wordlists: dict, corpus: Corpus, topics: list,\n",
    "    min_min: int = 1, max_min: int = 30,\n",
    "):\n",
    "    results = {}\n",
    "    for method, wordlist in wordlists.items():\n",
    "        if 'Subjective' in method:\n",
    "            hits = dr.match_wordlist(\n",
    "                corpus, wordlist, min=1,\n",
    "                escape=False, flags=re.IGNORECASE,\n",
    "            )\n",
    "        elif method == 'LLM-Regex':\n",
    "            hits = dr.match_regex(\n",
    "                corpus, wordlist, min=1,\n",
    "            )\n",
    "        else:\n",
    "            hits = dr.match_wordlist(\n",
    "                corpus, wordlist, min=1,\n",
    "            )\n",
    "        result = dr.eval_min(\n",
    "            corpus, hits, 'gold_label',\n",
    "            min_min=min_min,\n",
    "            max_min=max_min,\n",
    "            topic=topics,\n",
    "        )\n",
    "        results[method] = result\n",
    "    return results\n",
    "\n",
    "results_maintpc = results_for_methods(\n",
    "    wordlists, corpus, topics=['1_hauptthema'],\n",
    "    min_min=1, max_min=25,\n",
    ")\n",
    "results_sidetpc = results_for_methods(\n",
    "    wordlists, corpus, topics=['1_hauptthema', '2_nebenthema'],\n",
    "    min_min=1, max_min=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a function to plot the results as a line graph and run it for main and side topic queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def print_plot(\n",
    "    results: dict, skip_methods: list = None,\n",
    "    xlabel: str = 'Aggregate Frequency Threshold',\n",
    "    ylabel: str = 'F1 Score',\n",
    "):\n",
    "    # Translate some method names to more readable names\n",
    "    metric_to_name = {\n",
    "        'odds_ratio': 'Odds Ratio',\n",
    "        'log_likelihood_rayson': 'Log Likelihood',\n",
    "        'rqtr': 'RQTR',\n",
    "        'Baseline': 'Baseline',\n",
    "        'Subjective (2)': 'Subjective (2)',\n",
    "        'coll-Absatz-logdice': 'LogDice (Paragraph)',\n",
    "        'coll-Absatz-npmi': 'nPMI (Paragraph)',\n",
    "    }\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    palette = sns.color_palette(\"tab10\")\n",
    "    line_styles = ['-', '--', '-.', ':']\n",
    "    marker_styles = ['o', 's', '^']\n",
    "\n",
    "    results = {\n",
    "        method: result for method, result in results.items()\n",
    "        if method not in skip_methods\n",
    "    }\n",
    "\n",
    "    for idx, (method, result) in enumerate(results.items()):\n",
    "        i_values = list(result.keys())\n",
    "        f1_values = [result[i]['f1-score'] for i in i_values]\n",
    "        plt.plot(\n",
    "            i_values, f1_values,\n",
    "            label=f'{metric_to_name.get(method, method)}',\n",
    "            color=palette[idx],\n",
    "            linestyle=line_styles[idx % len(line_styles)],\n",
    "            linewidth=3,\n",
    "            marker=marker_styles[idx % len(marker_styles)],\n",
    "            markersize=8\n",
    "        )\n",
    "\n",
    "    plt.xlabel(xlabel, fontsize=20)\n",
    "    plt.ylabel(ylabel, fontsize=20)\n",
    "    plt.legend(fontsize=18, frameon=True)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "do_not_plot = [\n",
    "        'Subjective (1)',\n",
    "        'coll-5-logdice',\n",
    "        'coll-5-npmi',\n",
    "        'odds_ratio_BT2',\n",
    "        'log_likelihood_rayson_BT2',\n",
    "        'rqtr_BT2',\n",
    "        'LLM-Regex'\n",
    "]\n",
    "\n",
    "\n",
    "print_plot(\n",
    "    results_maintpc,\n",
    "    skip_methods=do_not_plot\n",
    ")\n",
    "print_plot(\n",
    "    results_sidetpc,\n",
    "    skip_methods=do_not_plot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above (test for different thresholds and then visualize) but for PMW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_for_methods_pmw(\n",
    "    wordlists: dict, corpus: Corpus, topics: list,\n",
    "    min_min: int = 500, max_min: int = 5000,\n",
    "    step: int = 500,\n",
    "):\n",
    "    results = {}\n",
    "    for method, wordlist in wordlists.items():\n",
    "\n",
    "        if 'Subjective' in method:\n",
    "            hits = dr.match_wordlist_pmw(\n",
    "                corpus, wordlist, min_pmw=1,\n",
    "                escape=False, flags=re.IGNORECASE,\n",
    "            )\n",
    "        elif method == 'LLM-Regex':\n",
    "            hits = dr.match_regex_pmw(\n",
    "                corpus, wordlist, min_pmw=1,\n",
    "            )\n",
    "        else:\n",
    "            hits = dr.match_wordlist_pmw(\n",
    "                corpus, wordlist, min_pmw=1,\n",
    "            )\n",
    "\n",
    "        result = dr.eval_min_pmw(\n",
    "            corpus, hits, 'gold_label',\n",
    "            min_min=min_min,\n",
    "            max_min=max_min,\n",
    "            steps=step,\n",
    "            topic=topics,\n",
    "        )\n",
    "\n",
    "        results[method] = result\n",
    "\n",
    "    return results\n",
    "\n",
    "results_pmw_maintpc = results_for_methods_pmw(\n",
    "    wordlists, corpus, topics=['1_hauptthema'],\n",
    "    min_min=1000, max_min=40001,\n",
    "    step=1000,\n",
    ")\n",
    "results_pmw_sidetpc = results_for_methods_pmw(\n",
    "    wordlists, corpus, topics=['1_hauptthema', '2_nebenthema'],\n",
    "    min_min=1000, max_min=40001,\n",
    "    step=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_plot(\n",
    "    results_pmw_maintpc,\n",
    "    skip_methods=do_not_plot,\n",
    "        xlabel='PMW Frequency Threshold',\n",
    ")\n",
    "print_plot(\n",
    "    results_pmw_sidetpc,\n",
    "    skip_methods=do_not_plot,\n",
    "        xlabel='PMW Frequency Threshold',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results in a table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_results_df(\n",
    "    results_maintpc, results_pmw_maintpc, min_thresholds=[1, 3, 5], pmw_value=10000\n",
    "):\n",
    "    columns = pd.MultiIndex.from_product([\n",
    "        [f'min {thresh}' for thresh in min_thresholds] + [f'pmw {pmw_value}'],\n",
    "        ['precision', 'recall', 'f1-score']\n",
    "    ])\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for method, evals in results_maintpc.items():\n",
    "        row_data = []\n",
    "\n",
    "        for thresh in min_thresholds:\n",
    "            row_data.extend([\n",
    "                evals[thresh]['precision'],\n",
    "                evals[thresh]['recall'],\n",
    "                evals[thresh]['f1-score']\n",
    "            ])\n",
    "\n",
    "        row_data.extend([\n",
    "            results_pmw_maintpc[method][pmw_value]['precision'],\n",
    "            results_pmw_maintpc[method][pmw_value]['recall'],\n",
    "            results_pmw_maintpc[method][pmw_value]['f1-score']\n",
    "        ])\n",
    "\n",
    "        df.loc[method] = row_data\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = create_results_df(\n",
    "    results_maintpc,\n",
    "    results_pmw_maintpc,\n",
    "    min_thresholds=[1, 5],\n",
    "    pmw_value=9000\n",
    ")\n",
    "df = df.round(3)\n",
    "\n",
    "row_order = [\n",
    "    'Baseline', 'Subjective (1)', 'Subjective (2)',\n",
    "    'coll-5-logdice', 'coll-5-npmi', 'coll-Absatz-logdice', 'coll-Absatz-npmi',\n",
    "    'log_likelihood_rayson', 'log_likelihood_rayson_BT2', 'odds_ratio', 'odds_ratio_BT2',\n",
    "    'rqtr', 'rqtr_BT2',\n",
    "    'LLM-Regex'\n",
    "]\n",
    "# Sort the DataFrame according to row_order\n",
    "df = df.reindex(row_order)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also copy and paste them when they are comma-separated (e.g. in Excel, Google Sheets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_df = df.copy()\n",
    "flat_df.columns = [f\"{col[0]}_{col[1]}\" for col in df.columns]\n",
    "flat_df = flat_df.reset_index().rename(columns={'index': 'method'})\n",
    "\n",
    "print(flat_df.to_csv(index=False), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
