{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d20411",
   "metadata": {},
   "source": [
    "# LLM-Eval\n",
    "Use LM-labelled data and pre-computed base queries to evaluate LLM performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "from src.corpus_creation import document_retriever as dr\n",
    "from src.load_data import load_files\n",
    "from src.corpus import Corpus\n",
    "from src.misc import custom_queries\n",
    "import re\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the path to the directory containing the corpus files here\n",
    "CORPUSDIR = '/home//.../final_corpus'\n",
    "\n",
    "docs, metadata = load_files(CORPUSDIR)\n",
    "corpus = Corpus(docs, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed884f",
   "metadata": {},
   "source": [
    "Load wordlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67cb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wordlists/queries/odds_ratio.txt', 'r') as f:\n",
    "    queries = f.readlines()\n",
    "query = [ast.literal_eval(q) for q in queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8a97b",
   "metadata": {},
   "source": [
    "Find documents in the corpus matching the query and then filter out using the LLM-labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = dr.match_wordlist(\n",
    "    corpus,\n",
    "    query,\n",
    "    min=1,\n",
    "    unique=False,\n",
    "    escape=False,\n",
    ")\n",
    "\n",
    "llm_hits = {}\n",
    "\n",
    "for i, hit in hits.items():\n",
    "    if corpus.metadata[i].get('GPT4o') in {'1_hauptthema'}:\n",
    "        llm_hits[i] = hit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825bb06",
   "metadata": {},
   "source": [
    "Evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.eval_retrieval(\n",
    "    corpus,\n",
    "    llm_hits,\n",
    "    'gold_label',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
