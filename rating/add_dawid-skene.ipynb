{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fae6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197944b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home//.../final_corpus')\n",
    "for json_file in path.glob('*.json'):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for annotator in ['student_annotator_1', 'student_annotator_2', 'expert_annotator_1', 'expert_annotator_2']:\n",
    "        if not data.get(annotator):\n",
    "            continue\n",
    "        if data.get(annotator).startswith('2_'):\n",
    "            data[annotator] = '2_nebenthema'\n",
    "\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_dataframe = {}\n",
    "\n",
    "for json_file in path.glob('*.json'):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # get all annotators\n",
    "    annotators = {\n",
    "        'student_annotator_1': data.get('student_annotator_1'),\n",
    "        'student_annotator_2': data.get('student_annotator_2'),\n",
    "        'expert_annotator_1': data.get('expert_annotator_1'),\n",
    "        'expert_annotator_2': data.get('expert_annotator_2')\n",
    "    }\n",
    "\n",
    "    # remove None values\n",
    "    annotators = {k: v for k, v in annotators.items() if v is not None}\n",
    "    \n",
    "    annotation_dataframe[json_file.stem] = annotators\n",
    "\n",
    "df = pd.DataFrame.from_dict(annotation_dataframe, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dawid_skene_model import list2array\n",
    "from dawid_skene_model import DawidSkeneModel\n",
    "\n",
    "# Define mapping from text labels to numeric classes\n",
    "label_mapping = {\n",
    "    '1_hauptthema': 0,\n",
    "    '2_nebenthema': 1,\n",
    "    '3_kein_thema': 2\n",
    "}\n",
    "reverse_mapping = {v: k for k, v in label_mapping.items()}\n",
    "class_num = len(label_mapping)\n",
    "\n",
    "# Transform DataFrame to the correct format for list2array\n",
    "dataset_list = []\n",
    "items = []\n",
    "\n",
    "for item in df.index:\n",
    "    # For each item/task, create a list of annotations per worker\n",
    "    worker_annotations = [[] for _ in range(len(df.columns))]\n",
    "    has_annotations = False\n",
    "\n",
    "    for worker_idx, worker in enumerate(df.columns):\n",
    "        label = df.loc[item, worker]\n",
    "        if pd.notna(label):\n",
    "            # Add the class index to this worker's annotations\n",
    "            worker_annotations[worker_idx].append(label_mapping[label])\n",
    "            has_annotations = True\n",
    "\n",
    "    if has_annotations:\n",
    "        dataset_list.append(worker_annotations)\n",
    "        items.append(item)\n",
    "\n",
    "# Run Dawid-Skene model\n",
    "dataset_tensor = list2array(class_num, dataset_list)\n",
    "model = DawidSkeneModel(class_num, max_iter=45, tolerance=10e-100)\n",
    "marginal_predict, error_rates, worker_reliability, predict_label = model.run(dataset_tensor)\n",
    "\n",
    "result_df = df.copy()\n",
    "result_df['dawid_skene_label'] = np.nan\n",
    "\n",
    "# Add Dawid-Skene predictions to the DataFrame\n",
    "for i, item in enumerate(items):\n",
    "    # Get the class with highest probability from predict_label\n",
    "    label_index = np.argmax(predict_label[i])\n",
    "    result_df.loc[item, 'dawid_skene_label'] = reverse_mapping[label_index]\n",
    "\n",
    "    for class_idx in range(class_num):\n",
    "        col_name = f'prob_{reverse_mapping[class_idx]}'\n",
    "        result_df.loc[item, col_name] = predict_label[i, class_idx]\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe06b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see who's most reliable...\n",
    "print(worker_reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9073bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for disagreements between Dawid-Skene and expert annotators\n",
    "result_df['expert_agreement'] = pd.NA\n",
    "expert_cols = ['expert_annotator_1', 'expert_annotator_2']\n",
    "\n",
    "for idx in result_df.index:\n",
    "    ds_label = result_df.loc[idx, 'dawid_skene_label']\n",
    "    if pd.isna(ds_label):\n",
    "        continue\n",
    "    expert_annotations = [result_df.loc[idx, col] for col in expert_cols if pd.notna(result_df.loc[idx, col])]\n",
    "\n",
    "    if expert_annotations:\n",
    "        result_df.loc[idx, 'expert_agreement'] = ds_label in expert_annotations\n",
    "\n",
    "disagreement_count = sum(result_df['expert_agreement'] == False)\n",
    "print(f\"Number of disagreements between Dawid-Skene and expert annotators: {disagreement_count}\")\n",
    "\n",
    "disagreements = result_df[result_df['expert_agreement'] == False]\n",
    "print(\"\\nItems where experts disagree with Dawid-Skene:\")\n",
    "print(disagreements[expert_cols + ['dawid_skene_label']])\n",
    "\n",
    "no_expert_count = sum(result_df['expert_agreement'].isna() & result_df['dawid_skene_label'].notna())\n",
    "print(f\"\\nNumber of items with Dawid-Skene label but no expert annotations: {no_expert_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53bf6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Are you sure you want to write into the files?\")\n",
    "# add dawid_skene labels to json files\n",
    "for json_file in path.glob('*.json'):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    filename = json_file.stem\n",
    "\n",
    "    if filename in result_df.index:\n",
    "        data['gold_label'] = result_df.loc[filename, 'dawid_skene_label']\n",
    "        with open(json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
